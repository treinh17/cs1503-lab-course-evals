{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc65c1ac-a55a-4006-b137-43b6cf2d3bbb",
   "metadata": {},
   "source": [
    "# Skill lab: Comparing classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0922d-6266-4e9f-98ca-5031daf253d0",
   "metadata": {},
   "source": [
    "In this assignment you will apply the statistical tools we learned to a machine learning task of comparing performance of two classifiers.\n",
    "\n",
    "By the end of this lab you will know\n",
    "- How to implement a k-nearest neighbor classifier.\n",
    "- How to perform a k-fold cross validation.\n",
    "- How to find confidence intervals for a classiifer performance based on a sample.\n",
    "- How to statistically compare performance of two classsifiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e80c23-0344-429e-a59a-a9c2ffc0c938",
   "metadata": {},
   "source": [
    "You need to perform the following seven tasks:\n",
    "1. Compute the accuracy of the Naive Bayes classifier based on the holdout estimation. Next, compute the confidence interval for accuracy at the confidence level 0.90.\n",
    "2. Break the original dataset into 10 folds for cross-validation of Naive Bayes classifier. Obtain classification results from 10 cross-validation experiments.\n",
    "3. Implement the Nearest Neighbors classifier. \n",
    "4. Use it to find the accuracy based on the holdout estimation. Compute the confidence interval at the confidence level 0.90. \n",
    "5. Generate the same 10-folds from a dataset with all numeric attributes and obtain classification results using the k-NN classifer. \n",
    "6. Test the hypothesis that two classifers have a diferent performance at significance level 0.05.\n",
    "7. Use the best classifier to predict the evaluation score of several instructors that you know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0eb93b-561f-4c12-9eb2-eefe2236edc8",
   "metadata": {},
   "source": [
    "Feel free to use any programming tools available: pandas, plain python, numpy or anything else. \n",
    "\n",
    "**You are not allowed to use sklearn or any other python library that already includes the implementation of all these tasks**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aff16f-0f60-4214-aa6c-da0b046a2cd8",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2fba9-4b17-4f44-a933-e49bfabe2d5b",
   "metadata": {},
   "source": [
    "The dataset for this lab contains about 460 anonymized student evaluations collected at the University of Texas at Austin, and used in the following publication: \"Beauty in the Classroom: Instructors' Pulchritude and Putative Pedagogical Productivity\". You can learn how the data was collected and the meaning of various data attributes following [THIS LINK](https://chance.amstat.org/2013/04/looking-good/).\n",
    "\n",
    "We use a subset of attributes. This smaller subset of the original data is included in the repository. We want to build a classifier that &mdash; based on these attributes &mdash; will predict the evaluation result for each instructor: good (&ge; 4) or bad (<4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db48b60-0f61-4053-961f-f771c02a931b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file = \"SStudentEvaluations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "71d0728c-ffd0-4248-8bb7-1ecc85f7f794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'bty_avg',\n",
      "       'eval_categorical'],\n",
      "      dtype='object')\n",
      "rank                 object\n",
      "ethnicity            object\n",
      "gender               object\n",
      "language             object\n",
      "age                   int64\n",
      "bty_avg             float64\n",
      "eval_categorical     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data.columns)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f232e92e-bf9c-41e2-ac2e-611605488dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>language</th>\n",
       "      <th>age</th>\n",
       "      <th>bty_avg</th>\n",
       "      <th>eval_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>english</td>\n",
       "      <td>36</td>\n",
       "      <td>5.000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>english</td>\n",
       "      <td>36</td>\n",
       "      <td>5.000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>english</td>\n",
       "      <td>36</td>\n",
       "      <td>5.000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>english</td>\n",
       "      <td>36</td>\n",
       "      <td>5.000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tenured</td>\n",
       "      <td>not minority</td>\n",
       "      <td>male</td>\n",
       "      <td>english</td>\n",
       "      <td>59</td>\n",
       "      <td>3.000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>not minority</td>\n",
       "      <td>male</td>\n",
       "      <td>english</td>\n",
       "      <td>32</td>\n",
       "      <td>6.833</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>non-english</td>\n",
       "      <td>42</td>\n",
       "      <td>5.333</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>non-english</td>\n",
       "      <td>42</td>\n",
       "      <td>5.333</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>non-english</td>\n",
       "      <td>42</td>\n",
       "      <td>5.333</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tenure track</td>\n",
       "      <td>minority</td>\n",
       "      <td>female</td>\n",
       "      <td>non-english</td>\n",
       "      <td>42</td>\n",
       "      <td>5.333</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank     ethnicity  gender     language  age  bty_avg  \\\n",
       "0    tenure track      minority  female      english   36    5.000   \n",
       "1    tenure track      minority  female      english   36    5.000   \n",
       "2    tenure track      minority  female      english   36    5.000   \n",
       "3    tenure track      minority  female      english   36    5.000   \n",
       "4         tenured  not minority    male      english   59    3.000   \n",
       "..            ...           ...     ...          ...  ...      ...   \n",
       "458  tenure track  not minority    male      english   32    6.833   \n",
       "459  tenure track      minority  female  non-english   42    5.333   \n",
       "460  tenure track      minority  female  non-english   42    5.333   \n",
       "461  tenure track      minority  female  non-english   42    5.333   \n",
       "462  tenure track      minority  female  non-english   42    5.333   \n",
       "\n",
       "    eval_categorical  \n",
       "0               good  \n",
       "1                bad  \n",
       "2                bad  \n",
       "3               good  \n",
       "4               good  \n",
       "..               ...  \n",
       "458             good  \n",
       "459              bad  \n",
       "460              bad  \n",
       "461              bad  \n",
       "462             good  \n",
       "\n",
       "[463 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a75ac-34c0-4397-a8c8-6190877df71f",
   "metadata": {},
   "source": [
    "First of all, we will shuffle the data. We use a seeded randomization &mdash; so we can obtain reproducible results (needed for testing of your work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623220bb-1fe8-46c1-a568-4f0edf9a8703",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>language</th>\n",
       "      <th>age</th>\n",
       "      <th>bty_avg</th>\n",
       "      <th>eval_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tenured</td>\n",
       "      <td>not minority</td>\n",
       "      <td>male</td>\n",
       "      <td>english</td>\n",
       "      <td>64</td>\n",
       "      <td>2.333</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tenured</td>\n",
       "      <td>not minority</td>\n",
       "      <td>female</td>\n",
       "      <td>english</td>\n",
       "      <td>46</td>\n",
       "      <td>4.333</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tenured</td>\n",
       "      <td>not minority</td>\n",
       "      <td>male</td>\n",
       "      <td>english</td>\n",
       "      <td>54</td>\n",
       "      <td>2.333</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>teaching</td>\n",
       "      <td>not minority</td>\n",
       "      <td>male</td>\n",
       "      <td>english</td>\n",
       "      <td>37</td>\n",
       "      <td>4.333</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tenured</td>\n",
       "      <td>not minority</td>\n",
       "      <td>male</td>\n",
       "      <td>english</td>\n",
       "      <td>64</td>\n",
       "      <td>2.333</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rank     ethnicity  gender language  age  bty_avg eval_categorical\n",
       "331   tenured  not minority    male  english   64    2.333              bad\n",
       "101   tenured  not minority  female  english   46    4.333             good\n",
       "192   tenured  not minority    male  english   54    2.333             good\n",
       "66   teaching  not minority    male  english   37    4.333              bad\n",
       "327   tenured  not minority    male  english   64    2.333              bad"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac = 1, random_state=1)    # shuffling the data before performing any validation\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943d690-a0d8-41e8-bd3e-34672b0de8cc",
   "metadata": {},
   "source": [
    "### Holdout estimation\n",
    "That is how we can divide the dataset into training and testing sets in proportion of ~ 2:1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9effe48-6b19-4dc9-9235-43f8b15af1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select ratio\n",
    "ratio = 0.66\n",
    " \n",
    "total_rows = data.shape[0]\n",
    "train_size = int(total_rows*ratio)\n",
    " \n",
    "# Split data into test and train\n",
    "data_train = data[0:train_size]\n",
    "data_test = data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebbf6bb4-de4a-443c-820f-34ea9e73a6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33755b32-9e8f-4433-bd0e-b960ca84146d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f819b-1a8c-43b3-a708-9db1dd4a958b",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711156d4-90c9-47c0-9530-09aa09df56f6",
   "metadata": {},
   "source": [
    "Below we provide our implementation of the first classifier: Naive Bayes.\n",
    "\n",
    "We have a mix of cathegorical and numeric attributes. We will produce counts and probabilities for cathegorical attributes. We will also precompute the mean and standard deviation for the numeric attributes which we will later use with the normal distribution probability density function (PDF) to compute the contribution of numeric attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7a384-fcd6-4562-a416-ace8f7b340aa",
   "metadata": {},
   "source": [
    "Here is an implementation of the PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418cb17e-30ca-4c46-a1c6-ffb0f589ada0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "def normal_pdf(x, stat):\n",
    "    \"\"\"\n",
    "    :param x: a variable\n",
    "    :param mean: µ - the expected value or average from M samples\n",
    "    :param stdev: σ - standard deviation\n",
    "    :return: Gaussian (Normal) Density function.\n",
    "    N(x; µ, σ) = (1 / 2πσ) * (e ^ (x–µ)^2/-2σ^2\n",
    "    \"\"\"\n",
    "    mean, stdev = stat\n",
    "    variance = stdev ** 2\n",
    "    exp_squared_diff = (x - mean) ** 2\n",
    "    exp_power = -exp_squared_diff / (2 * variance)\n",
    "    exponent = e ** exp_power\n",
    "    denominator = ((2 * pi) ** .5) * stdev\n",
    "    normal_prob = exponent / denominator\n",
    "    return normal_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadc050-fb3d-4363-b337-6a97f3975981",
   "metadata": {},
   "source": [
    "Here is our counting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b686ab6-46d4-4638-a7ef-700b1cf2b56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def produce_counts (train_set, column, results):\n",
    "    # counter = 5\n",
    "    col_idx = col_name_to_col_idx [column]\n",
    "    for tup in train_set.itertuples():\n",
    "        val = tup[col_idx]\n",
    "        class_label = tup[7]\n",
    "        prev = results [class_label][column]\n",
    "\n",
    "        if val not in prev.keys():\n",
    "            prev[val] = 0\n",
    "        prev[val] += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877380c-e76a-477f-8580-55b4bba651d2",
   "metadata": {},
   "source": [
    "Based on these counts, we can pre-compute conditional probabilities for all combinations of cathegorical attributes and class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9fd7b2-6474-4324-bfa9-1ef716d8e3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def produce_probabilities(counts, results, class_label, total):\n",
    "    for col in counts[class_label].keys():\n",
    "        results[class_label][col] = {} \n",
    "        cardinality = len(counts[class_label][col].keys())\n",
    "        \n",
    "        for val in counts[class_label][col].keys():\n",
    "            results[class_label][col][val] = (counts[class_label][col][val] + 1)/(total + cardinality)      \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d10e4-d062-4a2f-a957-b6c40d2d5862",
   "metadata": {},
   "source": [
    "The classification algorithm that classifies all the records in the *test_set*, based on the data in the *train_set*. \n",
    "\n",
    "The output is the list of classification results in form of a tuple (*classified*, *actual*), where *classified* is a class label obtained by our classification, and *actual* is the actual label of this record in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66776824-0182-4724-bcc8-8178ac8ea269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_name_to_col_idx = {\"rank\":1, \"ethnicity\":2, \"gender\":3, \"language\":4 }\n",
    "idx_to_col_name = {1:\"rank\", 2: \"ethnicity\", 3: \"gender\", 4: \"language\"}\n",
    "\n",
    "def naive_bayes_classify (train_set, test_set):  \n",
    "    counts = {\"good\": {\"rank\":{}, \"ethnicity\":{}, \"gender\":{}, \"language\":{}}, \"bad\":{\"rank\":{}, \"ethnicity\":{}, \"gender\":{}, \"language\":{}} }   \n",
    "\n",
    "    total_good  = train_set.groupby(\"eval_categorical\").size()[\"good\"]\n",
    "    total_bad = train_set.groupby(\"eval_categorical\").size()[\"bad\"]\n",
    "    priors = {\"good\":total_good/(total_good+total_bad), \"bad\":total_bad/(total_good+total_bad) }\n",
    "\n",
    "    for col in col_name_to_col_idx.keys():\n",
    "        produce_counts(train_set, col, counts)   \n",
    "    # print(counts)\n",
    "    \n",
    "    probs = {\"good\":{}, \"bad\":{}}\n",
    "    produce_probabilities (counts,  probs, \"good\", total_good)\n",
    "    produce_probabilities (counts,  probs, \"bad\", total_bad)\n",
    "    # print(probs)\n",
    "\n",
    "    # means and std for normal distribution of numeric parameters\n",
    "    data_good = train_set[train_set[\"eval_categorical\"]== \"good\"]\n",
    "    data_bad = train_set[train_set[\"eval_categorical\"]== \"bad\"]\n",
    "\n",
    "    stats = {\"good\":{\"age\":(data_good[\"age\"].mean(), data_good[\"age\"].std(ddof=1)), \n",
    "                 \"bty_avg\":(data_good[\"bty_avg\"].mean(), data_good[\"bty_avg\"].std(ddof=1)) },\n",
    "        \"bad\":{\"age\":(data_bad[\"age\"].mean(), data_bad[\"age\"].std(ddof=1)), \n",
    "                 \"bty_avg\":(data_bad[\"bty_avg\"].mean(), data_bad[\"bty_avg\"].std(ddof=1)) }}\n",
    "    #print(stats)\n",
    "    \n",
    "    results = []\n",
    "    for tup in test_set.itertuples():\n",
    "        class_label = tup[7]\n",
    "        prob_good = log (priors[\"good\"]) \n",
    "        for k in col_name_to_col_idx.keys():\n",
    "            prob_good += log (probs[\"good\"][k][tup[col_name_to_col_idx[k]]]) \n",
    "        prob_good += normal_pdf(tup[5], stats[\"good\"][\"age\"])\n",
    "        prob_good += normal_pdf(tup[6], stats[\"good\"][\"bty_avg\"])\n",
    "        # print (\"good:\", prob_good)\n",
    "\n",
    "        prob_bad = log (priors[\"bad\"]) \n",
    "        for k in col_name_to_col_idx.keys():\n",
    "            prob_bad += log (probs[\"bad\"][k][tup[col_name_to_col_idx[k]]]) \n",
    "        prob_bad += normal_pdf(tup[5], stats[\"bad\"][\"age\"])\n",
    "        prob_bad += normal_pdf(tup[6], stats[\"bad\"][\"bty_avg\"])\n",
    "        # print (\"bad:\", prob_bad)\n",
    "\n",
    "        classified_as = \"good\"\n",
    "        if prob_bad > prob_good:\n",
    "            classified_as = \"bad\"\n",
    "        \n",
    "        results += [(classified_as, class_label )]    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c48ce-9443-4a76-bec7-899f30d69a32",
   "metadata": {},
   "source": [
    "Let's run the classifier using the training and testing parts we obtained in the holdout section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3afb2c00-2a08-4e8a-98e7-0fd54baa21e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 'good'), ('good', 'good'), ('good', 'bad'), ('good', 'good'), ('bad', 'good')]\n",
      "Accuracy: 0.569620253164557\n"
     ]
    }
   ],
   "source": [
    "class_results = naive_bayes_classify(data_train, data_test)\n",
    "print(class_results[:5])\n",
    "\n",
    "correct_count = 0\n",
    "for r in range(len(class_results)):\n",
    "    if class_results[r][0] == class_results[r][1]:\n",
    "        correct_count+= 1\n",
    "print (\"Accuracy:\", correct_count/len(class_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba1b25-7fb6-4255-beb3-d411676025e8",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 1. Generate confidence interval for accuracy of the Naive Bayes</h3>    \n",
    "</div>\n",
    "You can write the code, or use the tables manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "911fdff8-7d8f-4231-8e0e-f4b9121ac4d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5048230914684971\n",
      "0.6344174148606169\n"
     ]
    }
   ],
   "source": [
    "accuracy = .569620253164557\n",
    "test_items = 158\n",
    "# confidence level 90%\n",
    "\n",
    "z = 1.645\n",
    "\n",
    "upper = accuracy + z*(math.sqrt((accuracy)*(1-accuracy)/test_items))\n",
    "lower = accuracy - z*(math.sqrt((accuracy)*(1-accuracy)/test_items))\n",
    "print(lower)\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdeb87e-fadf-41bd-bfb0-2c9eca0e16be",
   "metadata": {},
   "source": [
    "**Answer**: The confidence interval for the performance of the Naive Bayes classifier is: 0.5048230914684971, 0.6344174148606169"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4af64-97ed-4552-a5f5-1f8992408a94",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d29be-bc43-44ce-87c3-a7cedb3af7c1",
   "metadata": {},
   "source": [
    "We want to test the performance of two classifiers on different datasets &mdash; to get the mean of the paired difference. To create several traning/testing subsets we will use 10-fold cross-validation: we will divide our original dataset into 10 approximately equal parts (folds) and use 9 out of 10 folds for training and 1 fold for testing. Hence, the total number of performance experiments will be 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b5913-d713-48d9-a97d-063db0f70430",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 2. Perform the 10-fold cross-validation with Naive Bayes</h3>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa115d5a-db27-40c2-831f-43b8830c65c4",
   "metadata": {},
   "source": [
    "Generate 10 equal non-overlapping subsets of data and store them in the list of pandas data frames called *folds*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c64d220-ed86-42de-bddb-ea4e0aa65a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 size: 46\n",
      "Fold 1 size: 46\n",
      "Fold 2 size: 46\n",
      "Fold 3 size: 46\n",
      "Fold 4 size: 46\n",
      "Fold 5 size: 46\n",
      "Fold 6 size: 46\n",
      "Fold 7 size: 46\n",
      "Fold 8 size: 46\n",
      "Fold 9 size: 46\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "size = int(460/10)\n",
    "folds = []\n",
    "\n",
    "# TODO - your code\n",
    "for i in range(9):\n",
    "    folds += [data[i*size:(i+1)*size]]\n",
    "folds += [data[9*size:len(data)-3]]\n",
    "for i in range(k):\n",
    "    print(\"Fold\", i, \"size:\", folds[i].shape[0])\n",
    "    \n",
    "#display(folds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd9347-b668-4c4f-b40c-ab5faa303424",
   "metadata": {},
   "source": [
    "Implement the loop where you obtain classification results for each of the folds. Store these results in the list *nb_accuracies* for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e34d44f9-c5fa-4dfc-9b28-e77372f315df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6086956521739131, 0.5217391304347826, 0.5434782608695652, 0.6956521739130435, 0.5434782608695652, 0.41304347826086957, 0.4782608695652174, 0.5869565217391305, 0.6521739130434783, 0.45652173913043476]\n"
     ]
    }
   ],
   "source": [
    "nb_accuracies = []\n",
    "# TODO: your code\n",
    "#test_set = np.concatenate(folds[0],folds[1])\n",
    "\n",
    "def rotate(l, n):\n",
    "    return l[n:] + l[:n]\n",
    "\n",
    "list = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "for i in range(10):\n",
    "    list = rotate(list,1)\n",
    "    frames = [folds[list[1]],folds[list[2]],folds[list[3]],folds[list[4]],folds[list[5]],folds[list[6]],folds[list[7]],folds[list[8]],folds[list[9]]]\n",
    "    training_set = pd.concat(frames)\n",
    "    test_set = folds[list[0]]\n",
    "    class_results = naive_bayes_classify(training_set, test_set)\n",
    "    #print(class_results[:5])\n",
    "\n",
    "    correct_count = 0\n",
    "    for r in range(len(class_results)):\n",
    "        if class_results[r][0] == class_results[r][1]:\n",
    "            correct_count+= 1\n",
    "    accuracy = correct_count/len(class_results)\n",
    "    #print(accuracy)\n",
    "    nb_accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "\n",
    "print(nb_accuracies)\n",
    "#display(training_set)\n",
    "#display(test_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4c27e-cae8-456f-849a-8ce12704b1aa",
   "metadata": {},
   "source": [
    "For comparison &mdash; here are our results: 0.5652173913043478, 0.4782608695652174, 0.5217391304347826, 0.5652173913043478, \n",
    "    0.5217391304347826, 0.6956521739130435, 0.5434782608695652, 0.6086956521739131, 0.5434782608695652, 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e7c8b-4976-4fc3-93bb-929d8dd8fbad",
   "metadata": {},
   "source": [
    "Most of them are the same. I don't know why some of them are different. Maybe order or because of the randomization and then the numbers at the end that I got rid of because the folds weren't the same amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a48f03-426e-4c70-b0e8-aeb30cc2fa2e",
   "metadata": {},
   "source": [
    "## Nearest Neighbors classifier (k-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253b08d-0571-4558-b39c-6b44853363d5",
   "metadata": {},
   "source": [
    "This classifier assigns a class to a given record based on the class labels of *k* labeled records that are closest to it. The closest samples are selected based on a distance metric, then the neighbors vote and the majority class is assigned to a record in question.\n",
    "\n",
    "The value of *k* indicates the number of closest neighbors used to classify the test record. The value of *k* is non-parametric and a general rule of thumb in choosing the initial value of k is: k = sqrt(N)/2, where N stands for the number of samples in the training dataset. Another hint is to keep the value of k odd, so that there is no tie when choosing between two classes.\n",
    "\n",
    "For our dataset the size of the training set will be about 9 * 46 = 414, and sqrt(414)/2 is ~ 11. We will use k=11 nearest neighbors for our classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09000c-8b06-4cb7-a190-1c2425ed77e5",
   "metadata": {},
   "source": [
    "### Categorical to numeric (binary)\n",
    "To use distance metrics we must convert the categorical attributes to numeric. The most common method is to convert a categorical attribute into a set of binary attributes, such that for each categorical value there is a separate column, and the value in this column is either 0 or 1. This is called a \"one hot encoding\".\n",
    "\n",
    "One hot encoding for categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dafd04da-a6cd-43e9-8829-420aed3b1b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teaching</th>\n",
       "      <th>tenure track</th>\n",
       "      <th>tenured</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tenure track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tenure track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tenure track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tenure track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tenured</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   teaching  tenure track  tenured          rank\n",
       "0         0             1        0  tenure track\n",
       "1         0             1        0  tenure track\n",
       "2         0             1        0  tenure track\n",
       "3         0             1        0  tenure track\n",
       "4         0             0        1       tenured"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_rank = pd.get_dummies(data[\"rank\"], dtype=int)\n",
    "pd.concat([ohe_rank, data[\"rank\"]], axis=1, sort=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbd7116f-7927-43ce-af22-2d72bc68ea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minority</th>\n",
       "      <th>not minority</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not minority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minority  not minority     ethnicity\n",
       "0         1             0      minority\n",
       "1         1             0      minority\n",
       "2         1             0      minority\n",
       "3         1             0      minority\n",
       "4         0             1  not minority"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_ethnicity = pd.get_dummies(data[\"ethnicity\"], dtype=int)\n",
    "pd.concat([ohe_ethnicity, data[\"ethnicity\"]], axis=1, sort=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d91bf63b-e41a-4623-bdb3-2adf8dadb9af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   female  male  gender\n",
       "0       1     0  female\n",
       "1       1     0  female\n",
       "2       1     0  female\n",
       "3       1     0  female\n",
       "4       0     1    male"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_gender = pd.get_dummies(data[\"gender\"], dtype=int)\n",
    "pd.concat([ohe_gender, data[\"gender\"]], axis=1, sort=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b221889e-91e1-4e8a-9b43-3ced9b075b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>non-english</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   english  non-english language\n",
       "0        1            0  english\n",
       "1        1            0  english\n",
       "2        1            0  english\n",
       "3        1            0  english\n",
       "4        1            0  english"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_language = pd.get_dummies(data[\"language\"], dtype=int)\n",
    "pd.concat([ohe_language, data[\"language\"]], axis=1, sort=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8befedf-663a-45c0-bcfa-9ca60044d9e6",
   "metadata": {},
   "source": [
    "Now we create a dataset where all the cathegorical attributes are replaced by the binary columns. This dataset is called *num_data* and it will be used in the k-NN classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f1327bf-075c-4d51-bf1f-f86966c52a82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teaching</th>\n",
       "      <th>tenure track</th>\n",
       "      <th>tenured</th>\n",
       "      <th>minority</th>\n",
       "      <th>not minority</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>english</th>\n",
       "      <th>non-english</th>\n",
       "      <th>age</th>\n",
       "      <th>bty_avg</th>\n",
       "      <th>eval_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   teaching  tenure track  tenured  minority  not minority  female  male  \\\n",
       "0         0             1        0         1             0       1     0   \n",
       "1         0             1        0         1             0       1     0   \n",
       "2         0             1        0         1             0       1     0   \n",
       "3         0             1        0         1             0       1     0   \n",
       "4         0             0        1         0             1       0     1   \n",
       "\n",
       "   english  non-english  age  bty_avg eval_categorical  \n",
       "0        1            0   36      5.0             good  \n",
       "1        1            0   36      5.0              bad  \n",
       "2        1            0   36      5.0              bad  \n",
       "3        1            0   36      5.0             good  \n",
       "4        1            0   59      3.0             good  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = pd.concat([ohe_rank, ohe_ethnicity, ohe_gender, ohe_language, data[[\"age\",\"bty_avg\",\"eval_categorical\"]]], axis=1, sort=False)\n",
    "num_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79e16b-12ed-4bff-8b80-16b0f92dced9",
   "metadata": {},
   "source": [
    "Now all the data in num_data is numeric, and we can use the Euclidean distance to compute the distance between the records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1857a12-7ffb-4275-b7c2-45aba0383953",
   "metadata": {},
   "source": [
    "### Common scale\n",
    "You can see that the absolute values of different attributes are on different scales, and we better bring them all to the same interval between 0 and 1, since otherwise the difference in age will dominate an overall distance between two records.\n",
    "\n",
    "We transform numeric columns to a standard scale 0-1 using the following formula: x<sub>scaled</sub>=(x-min)/(max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a921b3e0-86c2-4768-919f-c11f5caa026b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply normalization techniques to column age \n",
    "column = 'age'\n",
    "num_data[column] = (num_data[column] - num_data[column].min()) / (num_data[column].max() - num_data[column].min())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "89ae9119-88c9-4c0b-a0d3-acdafe96bddf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teaching</th>\n",
       "      <th>tenure track</th>\n",
       "      <th>tenured</th>\n",
       "      <th>minority</th>\n",
       "      <th>not minority</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>english</th>\n",
       "      <th>non-english</th>\n",
       "      <th>age</th>\n",
       "      <th>bty_avg</th>\n",
       "      <th>eval_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.512769</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.512769</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.512769</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.512769</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.205077</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.794769</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     teaching  tenure track  tenured  minority  not minority  female  male  \\\n",
       "0           0             1        0         1             0       1     0   \n",
       "1           0             1        0         1             0       1     0   \n",
       "2           0             1        0         1             0       1     0   \n",
       "3           0             1        0         1             0       1     0   \n",
       "4           0             0        1         0             1       0     1   \n",
       "..        ...           ...      ...       ...           ...     ...   ...   \n",
       "458         0             1        0         0             1       0     1   \n",
       "459         0             1        0         1             0       1     0   \n",
       "460         0             1        0         1             0       1     0   \n",
       "461         0             1        0         1             0       1     0   \n",
       "462         0             1        0         1             0       1     0   \n",
       "\n",
       "     english  non-english       age   bty_avg eval_categorical  \n",
       "0          1            0  0.159091  0.512769             good  \n",
       "1          1            0  0.159091  0.512769              bad  \n",
       "2          1            0  0.159091  0.512769              bad  \n",
       "3          1            0  0.159091  0.512769             good  \n",
       "4          1            0  0.681818  0.205077             good  \n",
       "..       ...          ...       ...       ...              ...  \n",
       "458        1            0  0.068182  0.794769             good  \n",
       "459        0            1  0.295455  0.564000              bad  \n",
       "460        0            1  0.295455  0.564000              bad  \n",
       "461        0            1  0.295455  0.564000              bad  \n",
       "462        0            1  0.295455  0.564000             good  \n",
       "\n",
       "[463 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply normalization techniques to column bty_avg \n",
    "column = 'bty_avg'\n",
    "num_data[column] = (num_data[column] - num_data[column].min()) / (num_data[column].max() - num_data[column].min())     \n",
    "  \n",
    "# view normalized data \n",
    "display(num_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc7534-6259-4368-ae68-7d424e96d2bb",
   "metadata": {},
   "source": [
    "### Holdout for the numeric dataset\n",
    "Divide the dataset into training and testing sets in proportion of 2:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb00a7f2-e1cb-4404-bbb0-e02dd6448f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select ratio\n",
    "ratio = 0.66\n",
    " \n",
    "total_rows = num_data.shape[0]\n",
    "train_size = int(total_rows*ratio)\n",
    " \n",
    "# Split data into test and train\n",
    "num_data_train = num_data[0:train_size]\n",
    "num_data_test = num_data[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0afc29-4b9a-481a-a18b-b362b73dd40b",
   "metadata": {},
   "source": [
    "Now you have the input dataset for the k-NN classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23480ff3-90a3-48e6-aa6c-3365a6cbe962",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 3. Implement the k-NN classifier</h3>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e566a-18fc-4be2-a4a9-7a38192f43f2",
   "metadata": {},
   "source": [
    "Note that this is a \"lazy\" classifier and nothing can be precomputed. Both the training and the test sets are used only during classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abce20e-320f-4f81-b12b-895d92c36280",
   "metadata": {},
   "source": [
    "The output of a classifier should be the list of classification results in form of a tuple (*classified*, *actual*), where *classified* is a class label obtained by our classification, and *actual* is the actual label of this record in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a135efc2-c075-4d0d-86e9-fabc671fb938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "teaching                   0\n",
       "tenure track               1\n",
       "tenured                    0\n",
       "minority                   1\n",
       "not minority               0\n",
       "female                     1\n",
       "male                       0\n",
       "english                    1\n",
       "non-english                0\n",
       "age                 0.159091\n",
       "bty_avg             0.512769\n",
       "eval_categorical        good\n",
       "Name: 3, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "teaching                   0\n",
       "tenure track               0\n",
       "tenured                    1\n",
       "minority                   0\n",
       "not minority               1\n",
       "female                     0\n",
       "male                       1\n",
       "english                    1\n",
       "non-english                0\n",
       "age                 0.681818\n",
       "bty_avg             0.205077\n",
       "eval_categorical        good\n",
       "Name: 4, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row1 = num_data.iloc[3]\n",
    "display(row1)\n",
    "display(row1[0])\n",
    "row2 = num_data.iloc[4]\n",
    "display(row2)\n",
    "display(row2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8f7bf2d7-7354-4337-95f5-a227fa6367f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eucDistance(row1,row2):\n",
    "    total = 0\n",
    "    for i in range(11):\n",
    "        x = row1.iloc[i]\n",
    "        y = row2.iloc[i]\n",
    "        result = (x-y)**2\n",
    "        #print(result)\n",
    "        total += result\n",
    "    \n",
    "    total = math.sqrt(total)\n",
    "    \n",
    "    return total\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f04aa13b-90ea-466c-9cc1-ae9cd8a6edd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.523473470806838\n",
      "463\n"
     ]
    }
   ],
   "source": [
    "ans = eucDistance(row1,row2)\n",
    "print(ans)\n",
    "print(len(num_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2877f858-9ef0-4d63-a1d7-9b1b512cba41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neighbors(training,row,k,row_num):\n",
    "    row1 = row\n",
    "    #print(row)\n",
    "    x = len(training)\n",
    "    #print(x)\n",
    "    distances = []\n",
    "    for i in range(x):\n",
    "        if (i != row_num):\n",
    "            row2 = num_data.iloc[i]\n",
    "            #print(row2)\n",
    "            result = eucDistance(row1, row2)\n",
    "            #print(result)\n",
    "            distances.append([training.iloc[i],result])\n",
    "    #print(distances)\n",
    "    sorted_distances = sorted(distances,key=operator.itemgetter(1))\n",
    "    #print(sorted_distances)\n",
    "    #print(list(filter(lambda x: x[0] != 2, sorted_distances)))\n",
    "    \n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(sorted_distances[i][0])\n",
    "    \n",
    "    #print(neighbors)\n",
    "    #print(neighbors[0][0])\n",
    "    return neighbors\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2a26bed7-89f6-444d-9782-0629cbd2430a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 177, 178]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ans=neighbors(num_data,row1,5,3)\n",
    "display(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "bead5694-21f5-4cc9-baa8-8e454597bfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(neighbors):\n",
    "    good_bad = {}\n",
    "    for i in range(len(neighbors)):\n",
    "        good_or_bad = neighbors[i][-1]\n",
    "        if good_or_bad in good_bad:\n",
    "            good_bad[good_or_bad] += 1\n",
    "        else:\n",
    "            good_bad[good_or_bad] = 1\n",
    "        sorted_good_bad = sorted(good_bad.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return sorted_good_bad[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2c1d5bce-ce8e-4d2d-9f56-328bc3f44398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def isAccurate(test,prections):\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        if test[i][-1] in predictions[i]: \n",
    "            correct = correct + 1\n",
    "    return (correct / float(len(test)) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f05ff09f-3dc1-4120-a1f7-c3fb84286959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def knn_classify(train_set, test_set, knn):\n",
    "    predictions = []\n",
    "    results  = []\n",
    "    # TODO: your code here\n",
    "    for i in range(len(test_set)):\n",
    "        #print(test_set[i])\n",
    "        neighbors = get_neighbors(train_set,test_set.iloc[i],knn,i)\n",
    "        result = predict(neighbors)\n",
    "        predictions.append(result)\n",
    "        #print(result)\n",
    "        results +=[(result, test_set.iloc[i][-1])]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130ed67-ff6d-4e8d-94fd-c6357a3cf51d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 4. Generate the confidence interval for the k-NN accuracy </h3>    \n",
    "</div>\n",
    "This is based on the holdout estimation. \n",
    "Run your classifier, obtain the accuracy of the sample, and then produce a confidence interval. You can write the code, or use the tables manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "a0a396d2-878e-44cf-a1c7-44b40a81dea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teaching                   0\n",
      "tenure track               0\n",
      "tenured                    1\n",
      "minority                   0\n",
      "not minority               1\n",
      "female                     1\n",
      "male                       0\n",
      "english                    1\n",
      "non-english                0\n",
      "age                 0.318182\n",
      "bty_avg             0.256308\n",
      "eval_categorical         bad\n",
      "Name: 305, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(num_data_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4767e304-1fc4-4a55-8d15-4060284237f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 'bad'), ('good', 'good'), ('bad', 'bad'), ('bad', 'bad'), ('bad', 'bad')]\n",
      "Accuracy: 0.43037974683544306\n"
     ]
    }
   ],
   "source": [
    "#print(num_data_test[0])\n",
    "class_results = knn_classify(num_data_train, num_data_test, 11)\n",
    "print(class_results[:5])\n",
    "\n",
    "# TODO: classify and compute accuracy\n",
    "\n",
    "correct_count = 0\n",
    "for r in range(len(class_results)):\n",
    "    if class_results[r][0] == class_results[r][1]:\n",
    "        correct_count+= 1\n",
    "print (\"Accuracy:\", correct_count/len(class_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "238ac62a-adac-4055-9abc-89cc47f44ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36558258513938313\n",
      "0.495176908531503\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.43037974683544306\n",
    "test_items = 158\n",
    "# confidence level 90%\n",
    "\n",
    "z = 1.645\n",
    "\n",
    "upper = accuracy + z*(math.sqrt((accuracy)*(1-accuracy)/test_items))\n",
    "lower = accuracy - z*(math.sqrt((accuracy)*(1-accuracy)/test_items))\n",
    "print(lower)\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376416f1-acd1-476f-902a-4a24e261f463",
   "metadata": {},
   "source": [
    "Our accuracy was: 0.5569620253164557\n",
    "\n",
    "**Your answer**: The confidence interval for the performance of the k-NN classifier is: 0.36558258513938313, 0.495176908531503"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8813f2f-5591-4577-b83b-99fb53d204b0",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 5. Perform the 10-fold cross-validation with k-NN</h3>    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e322a68-5a19-444a-ae7d-c43e757d902b",
   "metadata": {},
   "source": [
    "Generate 10 equal non-overlapping subsets of numeric data from the numeric dataset and store them in the list of pandas data frames called *num_folds*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ad2e95bd-2d8b-4fae-a6c6-e67e7a7b6079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 size: 46\n",
      "Fold 1 size: 46\n",
      "Fold 2 size: 46\n",
      "Fold 3 size: 46\n",
      "Fold 4 size: 46\n",
      "Fold 5 size: 46\n",
      "Fold 6 size: 46\n",
      "Fold 7 size: 46\n",
      "Fold 8 size: 46\n",
      "Fold 9 size: 46\n"
     ]
    }
   ],
   "source": [
    "k = 10  # k here is the number of folds\n",
    "num_folds = []\n",
    "\n",
    "#TODO numeric folds\n",
    "for i in range(9):\n",
    "    num_folds += [num_data[i*size:(i+1)*size]]\n",
    "num_folds += [num_data[9*size:len(data)-3]]\n",
    "for i in range(k):\n",
    "    print(\"Fold\", i, \"size:\", num_folds[i].shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ca666-11ff-46bd-8b8c-d88359cd11bb",
   "metadata": {},
   "source": [
    "Implement the loop to perform 10-fold cross-validation. Store the classification results in the list *knn_accuracies* for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ae2163b5-0baf-4344-b4ef-5c7adeb65e02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7608695652173914\n",
      "0.5\n",
      "0.391304347826087\n",
      "0.32608695652173914\n",
      "0.30434782608695654\n",
      "0.6304347826086957\n",
      "0.782608695652174\n",
      "0.5652173913043478\n",
      "0.41304347826086957\n",
      "0.43478260869565216\n",
      "[0.7608695652173914, 0.5, 0.391304347826087, 0.32608695652173914, 0.30434782608695654, 0.6304347826086957, 0.782608695652174, 0.5652173913043478, 0.41304347826086957, 0.43478260869565216]\n"
     ]
    }
   ],
   "source": [
    "knn = 11 # knn here is the number of nearest neighbors\n",
    "knn_accuracies = []\n",
    "# TODO: your code here\n",
    "\n",
    "def rotate(l, n):\n",
    "    return l[n:] + l[:n]\n",
    "\n",
    "list = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "for i in range(10):\n",
    "    list = rotate(list,1)\n",
    "    frames = [num_folds[list[1]],num_folds[list[2]],num_folds[list[3]],num_folds[list[4]],num_folds[list[5]],num_folds[list[6]],num_folds[list[7]],num_folds[list[8]],num_folds[list[9]]]\n",
    "    training_set = pd.concat(frames)\n",
    "    #display(training_set)\n",
    "    test_set = num_folds[list[0]]\n",
    "    class_results = knn_classify(training_set, test_set, 11)\n",
    "    #print(class_results[:5])\n",
    "\n",
    "    correct_count = 0\n",
    "    for r in range(len(class_results)):\n",
    "        if class_results[r][0] == class_results[r][1]:\n",
    "            correct_count+= 1\n",
    "    accuracy = correct_count/len(class_results)\n",
    "    print(accuracy)\n",
    "    knn_accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "print (knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83628bf-916c-4059-9416-492ced7c12d9",
   "metadata": {},
   "source": [
    "Our results were:\n",
    "0.6304347826086957, 0.717391304347826, 0.5, 0.6304347826086957, 0.5869565217391305, 0.6304347826086957, \n",
    "0.717391304347826, 0.6521739130434783, 0.6956521739130435, 0.6739130434782609"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a5114-8f61-4e26-8e8e-e132f364f4dc",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 6. Compare performance of two classifiers</h3>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45efd6d-f14d-413d-b26b-9e7236cbb7bd",
   "metadata": {},
   "source": [
    "Based on the paired results stored in lists *nb_accuracies* and *knn_accuracies*, test the hypothesis that the two classifiers do not have the same performance at a significance level 0.05. Recall that we need to use the t-ditribution for the mean of differences. Again, you can either implement the computation or use the tables manually.\n",
    "\n",
    "**If you are not writing the code, please clearly explain all the steps of your computation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f12668-5269-4cd3-8400-d8cc461b529d",
   "metadata": {},
   "source": [
    "I can't seem to figure out where I went wrong so I am going to use the given results for the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "71c489a8-4b94-4448-bfbc-aca9f873df1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06521739  0.23913043 -0.02173913  0.06521739  0.06521739 -0.06521739\n",
      "  0.17391304  0.04347826  0.15217391  0.17391304]\n",
      "0.08913043478260871\n",
      "[-0.02391304  0.15       -0.11086957 -0.02391304 -0.02391304 -0.15434783\n",
      "  0.08478261 -0.04565217  0.06304348  0.08478261]\n",
      "[0.00057183 0.0225     0.01229206 0.00057183 0.00057183 0.02382325\n",
      " 0.00718809 0.00208412 0.00397448 0.00718809]\n",
      "0.08076559546313795\n",
      "0.09473096141948403\n",
      "2.9753227300843896\n"
     ]
    }
   ],
   "source": [
    "#ten fold cross validation\n",
    "n = 10\n",
    "t = 1.833 #significance level 0.05 and n-1 = 9\n",
    "\n",
    "nb = [0.5652173913043478, 0.4782608695652174, 0.5217391304347826, 0.5652173913043478, 0.5217391304347826, 0.6956521739130435, 0.5434782608695652, 0.6086956521739131, 0.5434782608695652, 0.5]\n",
    "knn = [0.6304347826086957, 0.717391304347826, 0.5, 0.6304347826086957, 0.5869565217391305, 0.6304347826086957, 0.717391304347826, 0.6521739130434783, 0.6956521739130435, 0.6739130434782609]\n",
    "\n",
    "dif = np.subtract(knn, nb) \n",
    "\n",
    "print(dif)\n",
    "\n",
    "dif_means = np.mean(dif)\n",
    "print(dif_means)\n",
    "\n",
    "dif_means2 = np.subtract(dif,dif_means)\n",
    "print(dif_means2)\n",
    "\n",
    "\n",
    "s_d = np.square(dif_means2)\n",
    "print(s_d)\n",
    "\n",
    "sum_s_d = np.sum(s_d)\n",
    "print(sum_s_d)\n",
    "\n",
    "s = np.sqrt(sum_s_d/9)\n",
    "print(s)\n",
    "\n",
    "test = (dif_means)/((s)/(np.sqrt(10)))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748250ef-c275-4f0a-94cc-2c336ec02c24",
   "metadata": {},
   "source": [
    "Test statistic is greater than the t value value so we would reject that there is not a significant difference. This proves that one of the classifiers is better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636b6bf-19a8-43a0-adea-c59421773d22",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 7. Use the best classifier</h3>    \n",
    "</div>\n",
    "Which classifier is significantly better? \n",
    "\n",
    "Use it to predict the evaluation results for instructors that you know.\n",
    "Now you can use the entire dataset as a training set.\n",
    "\n",
    "Did the predicted class labels correspond to your own evaluations? \n",
    "\n",
    "Discuss all these questions and add any notes about this lab in a separate cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bdac88-6940-4d3c-bb6a-0c6d6ada7596",
   "metadata": {},
   "source": [
    "The knn-classifier is significantly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "4c27823e-0def-4e29-8c75-c8bbd3f34e42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bad', 'good'), ('bad', 'bad'), ('good', 'good')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = [[0,0,1,1,0,1,0,0,1,0.295455,0.794769,'good'],[0,1,0,0,1,1,0,0,1,0.295455,0.794769,'bad'], [0,1,0,1,0,1,0,1,0,0.159091,0.205077,'good']]\n",
    "\n",
    "df = pd.DataFrame(test, columns=['teaching', 'tenure track','tenured','minority','not minority','female','male','english','non-english','age','bty_avg','eval_categorical'])\n",
    "\n",
    "class_results = knn_classify(num_data, df, 11)\n",
    "\n",
    "display(class_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39811f3b-8aa2-4fdd-93a3-feeaf916c654",
   "metadata": {},
   "source": [
    "2 of the 3 ended up being labled correct which was interesting. Although I wasn't able to fully get the correct numbers, this lab was interesting to kind of visualize how these types of classifiers can be utilized. It was very interesting to see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46caf0-3a4f-4658-8351-a31a033b9b2a",
   "metadata": {},
   "source": [
    "#### This is the end of the Skill lab 3. \n",
    "\n",
    "Copyright &copy; 2024 Marina Barsky."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
